{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "from pyemd import emd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/Users/Rutherford/Desktop/data\"\n",
    "epsilon = 1e-4\n",
    "\n",
    "binary_file = os.path.join(data_path,\n",
    "                           'GoogleNews-vectors-negative300.bin')\n",
    "w2v_dat = os.path.join(data_path,'embed.dat')\n",
    "w2v_vocab = os.path.join(data_path,'embed.vocab')\n",
    "\n",
    "# create word embeddings and mapping of vocabulary item to index\n",
    "embeddings = np.memmap(w2v_dat, dtype=np.float64,\n",
    "                            mode=\"r\", shape=(3000000, 300))\n",
    "with open(w2v_vocab) as f:\n",
    "    vocab_list = map(lambda string: string.strip(), f.readlines())\n",
    "vocab_dict = {w: i for i, w in enumerate(vocab_list)}\n",
    "\n",
    "# mean of 20 rarest words, used as a stand-in for pairwise distances\n",
    "# if a word is out-of-vocabulary\n",
    "avg_rare_word = np.mean(np.vstack(embeddings[-20:]),axis=0)\n",
    "bad_row = np.asarray([avg_rare_word])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_set = '/Users/Rutherford/Desktop/data/dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_dist(s_1,s_2):\n",
    "    \"\"\"Return counts of in-vocabulary and out-of-vocabulary items per\n",
    "    string, means of embeddings per string, and Word Mover's Distance\n",
    "    between the two. Word embeddings and mappings were created upon\n",
    "    initialization of the class instance, and WMD with emd()\n",
    "    (Earth Mover's Distance) from PyEMD. Final shape is [1,612].\n",
    "    \"\"\"\n",
    "\n",
    "    results_ = []\n",
    "\n",
    "    ###############\n",
    "    #s_1 = re.sub(r\"\\bs\\d{0,2}\\b\",'speaker',s_1)\n",
    "    #s_1 = re.sub(r\"\\b\\d{5,6}\\b\",'timestamp',s_1)\n",
    "    #s_1 = re.sub(r'\\d+','digit',s_1)\n",
    "    s_1 = re.sub(r'-',' ',s_1)\n",
    "    s_1 = re.sub(r\"\\ba\\b\",'one',s_1)\n",
    "\n",
    "    #s_2 = re.sub(r\"\\bs\\d{0,2}\\b\",'speaker',s_2)\n",
    "    #s_2 = re.sub(r\"\\b\\d{5,6}\\b\",'timestamp',s_2)\n",
    "    #s_2 = re.sub(r'\\d+','digit',s_2)\n",
    "    s_2 = re.sub(r'-',' ',s_2)\n",
    "    s_2 = re.sub(r\"\\ba\\b\",'one',s_2)\n",
    "\n",
    "\n",
    "    # from FuzzyWuzzy: ratio, partial, sort, set\n",
    "    fw_ratio = fuzz.ratio(s_1,s_2)\n",
    "    fw_partial = fuzz.partial_ratio(s_1,s_2)\n",
    "    fw_sort = fuzz.token_sort_ratio(s_1,s_2)\n",
    "    fw_set = fuzz.token_set_ratio(s_1,s_2)\n",
    "\n",
    "    # string lengths for each pair\n",
    "    str1_len = len(s_1)\n",
    "    str2_len = len(s_2)\n",
    "\n",
    "    # combine string metrics together and get scores from _get_dist()\n",
    "    string_metrics = [fw_ratio,fw_partial,fw_sort,fw_set,str1_len,str2_len]\n",
    "    results_.extend(string_metrics)\n",
    "\n",
    "    # moved this up here from mean of word embeddings section\n",
    "    s1_features = s_1.split()\n",
    "    s2_features = s_2.split()\n",
    "\n",
    "    # sum of indices; proxy for word rarity\n",
    "    ###results_.append(self._index_check(s1_features))\n",
    "    ###results_.append(self._index_check(s2_features))        \n",
    "\n",
    "\n",
    "    # number of out-of-vocabulary and in-vocabulary items\n",
    "    #s_1_bad = sum(map(lambda word:word not in self.vocab_dict,s1_features))\n",
    "    #s_1_good = sum(map(lambda word:word in self.vocab_dict,s1_features))\n",
    "    #s_2_bad = sum(map(lambda word:word not in self.vocab_dict,s2_features))\n",
    "    #s_2_good = sum(map(lambda word:word in self.vocab_dict,s2_features))\n",
    "    ###results_.append(s_1_bad)\n",
    "    ###results_.append(s_1_good)\n",
    "    ###results_.append(s_2_bad)\n",
    "    ###results_.append(s_2_good)\n",
    "\n",
    "    # mean of word embeddings per string (0s if no items are in embeddings)\n",
    "    # shape is [1,300] per string\n",
    "    S1_ = embeddings[[vocab_dict[w] for w in s1_features if w in vocab_dict]]\n",
    "    S2_ = embeddings[[vocab_dict[w] for w in s2_features if w in vocab_dict]]\n",
    "    if S1_.shape[0]==0:\n",
    "        S1_ = np.zeros((1,300))+epsilon\n",
    "    if S2_.shape[0]==0:\n",
    "        S2_ = np.zeros((1,300))+epsilon\n",
    "    S1_ = np.asarray(np.mean(S1_,axis=0)).reshape([-1,1])\n",
    "    S2_ = np.asarray(np.mean(S2_,axis=0)).reshape([-1,1])\n",
    "    results_.extend(S1_)\n",
    "    results_.extend(S2_)\n",
    "    ###results_.append(cosine(S1_,S2_))\n",
    "\n",
    "    #try:\n",
    "    # fit CV on words with or without a single quote\n",
    "    vect = CountVectorizer(token_pattern='[\\w\\']+').fit([s_1, s_2])\n",
    "    features = np.asarray(vect.get_feature_names())\n",
    "\n",
    "    # get 'flow' vectors\n",
    "    v_1, v_2 = vect.transform([s_1, s_2])\n",
    "    v_1 = v_1.toarray().ravel().astype(np.float64)\n",
    "    v_2 = v_2.toarray().ravel().astype(np.float64)\n",
    "\n",
    "    # normalize vectors so as not to reward shorter strings in WMD\n",
    "    v_1 /= (v_1.sum()+epsilon)\n",
    "    v_2 /= (v_2.sum()+epsilon)\n",
    "\n",
    "    # for each out-of-vocabulary item, use the average of the 20\n",
    "    # rarest words' embeddings to represent it in the distance calc       \n",
    "    W_ = np.ndarray([0,300])\n",
    "\n",
    "    # get distance matrix for words in both strings\n",
    "    for w in features:\n",
    "        if w in vocab_dict:\n",
    "            W_ = np.append(W_,embeddings[[vocab_dict[w]]],axis=0)\n",
    "        else:\n",
    "            W_ = np.append(W_,bad_row,axis=0)\n",
    "\n",
    "    # use both euclidean and cosine dists (cosine dist is 1-cosine sim)\n",
    "    D_euclidean = euclidean_distances(W_).astype(np.float64)\n",
    "    D_cosine = 1.-cosine_similarity(W_,).astype(np.float64)\n",
    "\n",
    "    # using EMD (Earth Mover's Distance) from PyEMD\n",
    "    distances_euclidean = emd(v_1,v_2,D_euclidean)\n",
    "    distances_cosine = emd(v_1,v_2,D_cosine)\n",
    "\n",
    "    # both WMD calculations (euclidean and cosine)\n",
    "    results_.append(distances_euclidean)\n",
    "    results_.append(distances_cosine)\n",
    "\n",
    "    return results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = '/Users/Rutherford/Desktop/cleaning_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data generation from orginal nn\n",
    "\n",
    "# original training set cols are Error_type, Str_1, Str_2\n",
    "X_in = np.genfromtxt(training_set,\n",
    "              delimiter=',',usecols=(1,2),dtype=str)\n",
    "Y_in = np.genfromtxt(training_set,\n",
    "              delimiter=',',usecols=(0)).reshape((-1,1))\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "bad = []\n",
    "\n",
    "for i,strings in enumerate(X_in):\n",
    "    try:\n",
    "        scores = _get_dist(strings[0],strings[1])\n",
    "        X.extend(scores)\n",
    "\n",
    "        # target\n",
    "        Y.append(Y_in[i])\n",
    "    except:\n",
    "        bad.append(i)\n",
    "        continue\n",
    "\n",
    "X = np.asarray(X).reshape((-1,608))\n",
    "Y = np.asarray(Y).reshape((-1,1))\n",
    "\n",
    "# unshuffled indices\n",
    "indices = range(X.shape[0])\n",
    "\n",
    "# randomly shuffle the data\n",
    "np.random.seed(30)\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "\n",
    "# transform Y from either 1 or 2 to a one-hot vector ([1,0] or [0,1])\n",
    "y_list = []\n",
    "for i, label in enumerate(Y):\n",
    "    if label == 2:\n",
    "        label = 1\n",
    "        y_list.append(np.insert(label,0,0))\n",
    "    elif label == 1:\n",
    "        y_list.append(np.insert(label,1,0))\n",
    "    else:\n",
    "        raise ValueError(\"Y label must be either 1 (minor) or                                     2 (major). Problem at index \", indices[i])\n",
    "Y = np.asarray(y_list)\n",
    "\n",
    "#X,Y,indices,X_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.770214179148052, 0.8815654487685087]"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity checks for wmd distances\n",
    "print(_get_dist('carp','crap')[-2:])\n",
    "print(_get_dist('elude','allude')[-2:])\n",
    "print(_get_dist('dog','puppy')[-2:])\n",
    "print(_get_dist('snake','serpent')[-2:])\n",
    "print(_get_dist('this','that')[-2:])\n",
    "print(_get_dist('he','she')[-2:])\n",
    "print(_get_dist('and I ran','if I run')[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# playing with distance calculations.. using only a few features for RF\n",
    "\n",
    "def dist2(s_1,s_2):\n",
    "    \"\"\"Return counts of in-vocabulary and out-of-vocabulary items per\n",
    "    string, means of embeddings per string, and Word Mover's Distance\n",
    "    between the two. Word embeddings and mappings were created upon\n",
    "    initialization of the class instance, and WMD with emd()\n",
    "    (Earth Mover's Distance) from PyEMD. Final shape is [1,612].\n",
    "    \"\"\"\n",
    "\n",
    "    results_ = []\n",
    "\n",
    "    ###############\n",
    "    #s_1 = re.sub(r\"\\bs\\d{0,2}\\b\",'speaker',s_1)\n",
    "    #s_1 = re.sub(r\"\\b\\d{5,6}\\b\",'timestamp',s_1)\n",
    "    #s_1 = re.sub(r'\\d+','digit',s_1)\n",
    "    s_1 = re.sub(r'-',' ',s_1)\n",
    "    s_1 = re.sub(r\"\\ba\\b\",'one',s_1)\n",
    "\n",
    "    #s_2 = re.sub(r\"\\bs\\d{0,2}\\b\",'speaker',s_2)\n",
    "    #s_2 = re.sub(r\"\\b\\d{5,6}\\b\",'timestamp',s_2)\n",
    "    #s_2 = re.sub(r'\\d+','digit',s_2)\n",
    "    s_2 = re.sub(r'-',' ',s_2)\n",
    "    s_2 = re.sub(r\"\\ba\\b\",'one',s_2)\n",
    "\n",
    "    # string lengths for each pair\n",
    "    str1_len = len(s_1)\n",
    "    str2_len = len(s_2)\n",
    "\n",
    "    # combine string metrics together and get scores from _get_dist()\n",
    "    string_metrics = [str1_len,str2_len]\n",
    "    results_.extend(string_metrics)\n",
    "\n",
    "    # moved this up here from mean of word embeddings section\n",
    "    s1_features = s_1.split()\n",
    "    s2_features = s_2.split()\n",
    "\n",
    "    # sum of indices; proxy for word rarity\n",
    "    ###results_.append(self._index_check(s1_features))\n",
    "    ###results_.append(self._index_check(s2_features))        \n",
    "\n",
    "\n",
    "    # number of out-of-vocabulary and in-vocabulary items\n",
    "    #s_1_bad = sum(map(lambda word:word not in self.vocab_dict,s1_features))\n",
    "    #s_1_good = sum(map(lambda word:word in self.vocab_dict,s1_features))\n",
    "    #s_2_bad = sum(map(lambda word:word not in self.vocab_dict,s2_features))\n",
    "    #s_2_good = sum(map(lambda word:word in self.vocab_dict,s2_features))\n",
    "    ###results_.append(s_1_bad)\n",
    "    ###results_.append(s_1_good)\n",
    "    ###results_.append(s_2_bad)\n",
    "    ###results_.append(s_2_good)\n",
    "\n",
    "    # mean of word embeddings per string (0s if no items are in embeddings)\n",
    "    # shape is [1,300] per string\n",
    "    S1_ = embeddings[[vocab_dict[w] for w in s1_features if w in vocab_dict]]\n",
    "    S2_ = embeddings[[vocab_dict[w] for w in s2_features if w in vocab_dict]]\n",
    "    if S1_.shape[0]==0:\n",
    "        S1_ = np.zeros((1,300))+epsilon\n",
    "    if S2_.shape[0]==0:\n",
    "        S2_ = np.zeros((1,300))+epsilon\n",
    "    S1_ = np.asarray(np.mean(S1_,axis=0)).reshape([-1,1])\n",
    "    S2_ = np.asarray(np.mean(S2_,axis=0)).reshape([-1,1])\n",
    "    #results_.extend(S1_)\n",
    "    #results_.extend(S2_)\n",
    "    results_.append(cosine(S1_,S2_))\n",
    "\n",
    "    \"\"\"\n",
    "    #try:\n",
    "    # fit CV on words with or without a single quote\n",
    "    vect = CountVectorizer(token_pattern='[\\w\\']+').fit([s_1, s_2])\n",
    "    features = np.asarray(vect.get_feature_names())\n",
    "\n",
    "    # get 'flow' vectors\n",
    "    v_1, v_2 = vect.transform([s_1, s_2])\n",
    "    v_1 = v_1.toarray().ravel().astype(np.float64)\n",
    "    v_2 = v_2.toarray().ravel().astype(np.float64)\n",
    "\n",
    "    # normalize vectors so as not to reward shorter strings in WMD\n",
    "    v_1 /= (v_1.sum()+epsilon)\n",
    "    v_2 /= (v_2.sum()+epsilon)\n",
    "\n",
    "    # for each out-of-vocabulary item, use the average of the 20\n",
    "    # rarest words' embeddings to represent it in the distance calc       \n",
    "    W_ = np.ndarray([0,300])\n",
    "\n",
    "    # get distance matrix for words in both strings\n",
    "    for w in features:\n",
    "        if w in vocab_dict:\n",
    "            W_ = np.append(W_,embeddings[[vocab_dict[w]]],axis=0)\n",
    "        else:\n",
    "            W_ = np.append(W_,bad_row,axis=0)\n",
    "\n",
    "    # use both euclidean and cosine dists (cosine dist is 1-cosine sim)\n",
    "    D_euclidean = euclidean_distances(W_).astype(np.float64)\n",
    "    D_cosine = 1.-cosine_similarity(W_,).astype(np.float64)\n",
    "\n",
    "    # using EMD (Earth Mover's Distance) from PyEMD\n",
    "    distances_euclidean = emd(v_1,v_2,D_euclidean)\n",
    "    distances_cosine = emd(v_1,v_2,D_cosine)\n",
    "\n",
    "    # both WMD calculations (euclidean and cosine)\n",
    "    results_.append(distances_euclidean)\n",
    "    results_.append(distances_cosine)\n",
    "    \"\"\"\n",
    "    return results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = []\n",
    "Y2 = []\n",
    "bad2 = []\n",
    "\n",
    "for i,strings in enumerate(X_in):\n",
    "    try:\n",
    "        scores = dist2(strings[0],strings[1])\n",
    "        X2.extend(scores)\n",
    "\n",
    "        # target\n",
    "        Y2.append(Y_in[i])\n",
    "    except:\n",
    "        bad.append(i)\n",
    "        continue\n",
    "\n",
    "X2 = np.asarray(X2).reshape((-1,3))\n",
    "Y2 = np.asarray(Y2).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ysecond = Y_in.reshape([-1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# unshuffled indices\n",
    "indices2 = range(X2.shape[0])\n",
    "\n",
    "# randomly shuffle the data\n",
    "np.random.seed(30)\n",
    "np.random.shuffle(indices2)\n",
    "X2 = X2[indices2]\n",
    "Y2 = Ysecond[indices2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_size = .2\n",
    "test_size = .1\n",
    "# create split indices for validation, test, and train sets\n",
    "_validation_test_split_idx2 = int(len(Y2)*validation_size)\n",
    "_train_test_split_idx2 = int(len(Y2)*test_size)+_validation_test_split_idx2\n",
    "\n",
    "# split data\n",
    "x2_validation = X2[:_validation_test_split_idx2]\n",
    "x2_test = X2[_validation_test_split_idx2:\n",
    "                     _train_test_split_idx2]\n",
    "x2_train = X2[_train_test_split_idx2:]\n",
    "y2_validation = Y2[:_validation_test_split_idx2]\n",
    "y2_test = Y2[_validation_test_split_idx2:\n",
    "                     _train_test_split_idx2]\n",
    "y2_train = Y2[_train_test_split_idx2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-153b9fb5b352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86239024063275016"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x2_validation,y2_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617\n",
      "14302\n",
      "1580\n"
     ]
    }
   ],
   "source": [
    "print(sum(rf.predict(x2_validation)==2))\n",
    "print(sum(rf.predict(x2_validation)==1))\n",
    "print(sum(y2_validation==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FN_indices = np.where((y2_validation==2) & (rf.predict(x2_validation)==1))[0].tolist()\n",
    "TP_indices = np.where((y2_validation==2) & (rf.predict(x2_validation)==2))[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tester = []\n",
    "for i in FN_indices:\n",
    "    tester.append(indices2[:_validation_test_split_idx2][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1508"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TPs = [indices2[:_validation_test_split_idx2][i] for i in TP_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1580"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y2_validation==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Y_in[TPs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_in[TPs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist2(s_1,s_2):\n",
    "\n",
    "    results_ = []\n",
    "\n",
    "    ###############\n",
    "    #s_1 = re.sub(r\"\\bs\\d{0,2}\\b\",'speaker',s_1)\n",
    "    #s_1 = re.sub(r\"\\b\\d{5,6}\\b\",'timestamp',s_1)\n",
    "    #s_1 = re.sub(r'\\d+','digit',s_1)\n",
    "    s_1 = re.sub(r'-',' ',s_1)\n",
    "    s_1 = re.sub(r\"\\ba\\b\",'one',s_1)\n",
    "\n",
    "    #s_2 = re.sub(r\"\\bs\\d{0,2}\\b\",'speaker',s_2)\n",
    "    #s_2 = re.sub(r\"\\b\\d{5,6}\\b\",'timestamp',s_2)\n",
    "    #s_2 = re.sub(r'\\d+','digit',s_2)\n",
    "    s_2 = re.sub(r'-',' ',s_2)\n",
    "    s_2 = re.sub(r\"\\ba\\b\",'one',s_2)\n",
    "    \n",
    "    ##### FUZZIES\n",
    "    \n",
    "    # string lengths for each pair\n",
    "    str1_len = len(s_1)\n",
    "    str2_len = len(s_2)\n",
    "\n",
    "    # combine string metrics together and get scores from _get_dist()\n",
    "    string_metrics = [str1_len,str2_len]\n",
    "    results_.extend(string_metrics)\n",
    "\n",
    "    # moved this up here from mean of word embeddings section\n",
    "    s1_features = s_1.split()\n",
    "    s2_features = s_2.split()\n",
    "\n",
    "    # sum of indices; proxy for word rarity\n",
    "    ###results_.append(self._index_check(s1_features))\n",
    "    ###results_.append(self._index_check(s2_features))        \n",
    "\n",
    "\n",
    "    # number of out-of-vocabulary and in-vocabulary items\n",
    "    #s_1_bad = sum(map(lambda word:word not in self.vocab_dict,s1_features))\n",
    "    #s_1_good = sum(map(lambda word:word in self.vocab_dict,s1_features))\n",
    "    #s_2_bad = sum(map(lambda word:word not in self.vocab_dict,s2_features))\n",
    "    #s_2_good = sum(map(lambda word:word in self.vocab_dict,s2_features))\n",
    "    ###results_.append(s_1_bad)\n",
    "    ###results_.append(s_1_good)\n",
    "    ###results_.append(s_2_bad)\n",
    "    ###results_.append(s_2_good)\n",
    "    \n",
    "    #COSINE:\n",
    "    # mean of word embeddings per string (0s if no items are in embeddings)\n",
    "    # shape is [1,300] per string\n",
    "    S1_ = embeddings[[vocab_dict[w] for w in s1_features if w in vocab_dict]]\n",
    "    S2_ = embeddings[[vocab_dict[w] for w in s2_features if w in vocab_dict]]\n",
    "    if S1_.shape[0]==0:\n",
    "        S1_ = np.zeros((1,300))+epsilon\n",
    "    if S2_.shape[0]==0:\n",
    "        S2_ = np.zeros((1,300))+epsilon\n",
    "    S1_ = np.asarray(np.mean(S1_,axis=0)).reshape([-1,1])\n",
    "    S2_ = np.asarray(np.mean(S2_,axis=0)).reshape([-1,1])\n",
    "    #results_.extend(S1_)\n",
    "    #results_.extend(S2_)\n",
    "    results_.append(cosine(S1_,S2_))\n",
    "\n",
    "\n",
    "    #try:\n",
    "    # fit CV on words with or without a single quote\n",
    "    vect = CountVectorizer(token_pattern='[\\w\\']+').fit([s_1, s_2])\n",
    "    features = np.asarray(vect.get_feature_names())\n",
    "\n",
    "    # get 'flow' vectors\n",
    "    v_1, v_2 = vect.transform([s_1, s_2])\n",
    "    v_1 = v_1.toarray().ravel().astype(np.float64)\n",
    "    v_2 = v_2.toarray().ravel().astype(np.float64)\n",
    "\n",
    "    # normalize vectors so as not to reward shorter strings in WMD\n",
    "    v_1 /= (v_1.sum()+epsilon)\n",
    "    v_2 /= (v_2.sum()+epsilon)\n",
    "\n",
    "    # for each out-of-vocabulary item, use the average of the 20\n",
    "    # rarest words' embeddings to represent it in the distance calc       \n",
    "    W_ = np.ndarray([0,300])\n",
    "\n",
    "    # get distance matrix for words in both strings\n",
    "    for w in features:\n",
    "        if w in vocab_dict:\n",
    "            W_ = np.append(W_,embeddings[[vocab_dict[w]]],axis=0)\n",
    "        else:\n",
    "            W_ = np.append(W_,bad_row,axis=0)\n",
    "\n",
    "    # use both euclidean and cosine dists (cosine dist is 1-cosine sim)\n",
    "    D_euclidean = euclidean_distances(W_).astype(np.float64)\n",
    "    D_cosine = 1.-cosine_similarity(W_,).astype(np.float64)\n",
    "\n",
    "    # using EMD (Earth Mover's Distance) from PyEMD\n",
    "    distances_euclidean = emd(v_1,v_2,D_euclidean)\n",
    "    distances_cosine = emd(v_1,v_2,D_cosine)\n",
    "\n",
    "    # both WMD calculations (euclidean and cosine)\n",
    "    results_.append(distances_euclidean)\n",
    "    results_.append(distances_cosine)\n",
    "\n",
    "    return results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NO COSINE\n",
    "len(_get_dist('this','that'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_size = .2\n",
    "test_size = .1\n",
    "# create split indices for validation, test, and train sets\n",
    "_validation_test_split_idx = int(len(Y)*validation_size)\n",
    "_train_test_split_idx = int(len(Y)*test_size)+_validation_test_split_idx\n",
    "\n",
    "# split data\n",
    "x_validation = X[:_validation_test_split_idx]\n",
    "x_test = X[_validation_test_split_idx:\n",
    "                     _train_test_split_idx]\n",
    "x_train = X[_train_test_split_idx:]\n",
    "y_validation = Y[:_validation_test_split_idx]\n",
    "y_test = Y[_validation_test_split_idx:\n",
    "                     _train_test_split_idx]\n",
    "y_train = Y[_train_test_split_idx:]\n",
    "#print(x_validation.shape,x_test.shape,x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases, n_hidden):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(0, n_steps, x)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=.8, state_is_tuple=True)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tf.nn.rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 75#1000#000\n",
    "batch_size = 32\n",
    "display_step = 1\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 608 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 1 # timesteps\n",
    "num_hidden = 128#128 # hidden layer num of features\n",
    "n_classes = 2 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    '''\n",
    "    To classify images using a recurrent neural network, we consider every image\n",
    "    row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "    handle 28 sequences of 28 steps for every sample.\n",
    "    '''\n",
    "\n",
    "    # tf Graph input\n",
    "    x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "    y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "    # Define weights\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([num_hidden, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    start = time()\n",
    "    pred = RNN(x, weights, biases, num_hidden)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    #########J = sum(sum(6*(y*tf.log(pred))+(1-y)*tf.log(1-pred)))\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "    ##ratio = 8034.0 / (66561.0 + 8034.0)\n",
    "    #class_weight = tf.constant(1.-ratio)#, 1.0 - ratio\n",
    "    ##class_weight = tf.constant(-ratio)\n",
    "    ##cost = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(pred, y, pos_weight=class_weight))\n",
    "    ### doesn't work but cost = tf.reduce_mean(tf.square(tf.cast(tf.less(pred, y),dtype=tf.float32)))\n",
    "    \n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    return (x,y),cost,optimizer,pred,accuracy,learning_rate,tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_in==2)/(sum(Y_in==1)+sum(Y_in==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    tf.reset_default_graph()\n",
    "    (X,Y),cost,train_op,preds,accuracy,lr,saver = build_graph()\n",
    "\n",
    "    x_train_reshaped = x_train.reshape((-1,n_steps,n_input))\n",
    "    x_val_reshaped = x_validation.reshape((-1,n_steps,n_input))\n",
    "    x_test_reshaped = x_test.reshape((-1,n_steps,n_input))\n",
    "    #x_reshaped = x_train.reshape((-1,n_steps,n_input))\n",
    "    #x_val = x_validation.reshape((-1,n_steps,n_input))\n",
    "    #x_test_reshaped = x_test.reshape((-1,n_steps,n_input))\n",
    "    val_acc_list = [0]\n",
    "    tr_acc_list = [0]\n",
    "    val_cost_list = [0]\n",
    "    tr_cost_list = [0]\n",
    "\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        start_end = zip(range(0,len(x_train),batch_size),\n",
    "                   range(batch_size,len(x_train)+1,\n",
    "                         batch_size))\n",
    "        \n",
    "        for pass_i in range(training_iters):\n",
    "            for (s,e) in start_end:\n",
    "\n",
    "                \"\"\"batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                batch_x = batch_x.reshape((batch_size, n_steps, n_input))\"\"\"\n",
    "\n",
    "                ######x_batch = x_train[s:e,].reshape((batch_size,n_steps,n_input))\n",
    "                # Run optimization op (backprop)\n",
    "                sess.run(train_op, feed_dict={X: x_train_reshaped[s:e,:,:], Y: y_train[s:e]})\n",
    "                # Calculate batch accuracy\n",
    "                #train_acc = sess.run(accuracy, feed_dict={x: x_batch, y: y_train[s:e]})\n",
    "                # Calculate batch loss\n",
    "                #train_loss = sess.run(cost, feed_dict={x: x_batch, y: y_train[s:e]})\n",
    "\n",
    "            #print('validation accuracy: ',sess.run(accuracy, feed_dict={X: x_val_reshaped, Y: y_validation}))\n",
    "\n",
    "            tr_loss = sess.run(cost, feed_dict={X: x_train_reshaped, Y: y_train})\n",
    "            tr_acc = sess.run(accuracy, feed_dict={X: x_train_reshaped, Y: y_train})\n",
    "            val_loss = sess.run(cost, feed_dict={X: x_val_reshaped, Y: y_validation})\n",
    "            val_acc = sess.run(accuracy, feed_dict={X: x_val_reshaped, Y: y_validation})\n",
    "            #tes_loss = sess.run(cost, feed_dict={X: x_test_reshaped, Y: y_test})\n",
    "            #tes_acc = sess.run(accuracy, feed_dict={X: x_test_reshaped, Y: y_test})\n",
    "\n",
    "            print(\"Iter \" + str(pass_i) + \", Train Loss= \" + \\\n",
    "                  \"{:.6f}\".format(tr_loss) + \", Train Acc= \" + \\\n",
    "                  \"{:.5f}\".format(tr_acc) + \", Val Loss= \" + \\\n",
    "                  \"{:.6f}\".format(val_loss) + \", Val Acc= \" + \\\n",
    "                  \"{:.5f}\".format(val_acc)\n",
    "                 )\n",
    "            if val_acc > max(val_acc_list):\n",
    "                saver.save(sess,'/Users/Rutherford/Desktop/rnn models/model.ckpt')\n",
    "                print('model saved.')\n",
    "            \n",
    "            val_acc_list.append(val_acc)\n",
    "            tr_acc_list.append(tr_acc)\n",
    "            val_cost_list.append(val_loss)\n",
    "            tr_cost_list.append(tr_loss)\n",
    "\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "    return val_acc_list,val_cost_list,tr_acc_list,tr_cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Train Loss= 0.481986, Train Acc= 0.77189, Val Loss= 0.492145, Val Acc= 0.76576\n",
      "model saved.\n",
      "Iter 1, Train Loss= 0.467667, Train Acc= 0.78417, Val Loss= 0.478439, Val Acc= 0.77772\n",
      "model saved.\n",
      "Iter 2, Train Loss= 0.459910, Train Acc= 0.79085, Val Loss= 0.471175, Val Acc= 0.78475\n",
      "model saved.\n",
      "Iter 3, Train Loss= 0.454815, Train Acc= 0.79375, Val Loss= 0.466530, Val Acc= 0.78663\n",
      "model saved.\n",
      "Iter 4, Train Loss= 0.450947, Train Acc= 0.79588, Val Loss= 0.463111, Val Acc= 0.78837\n",
      "model saved.\n",
      "Iter 5, Train Loss= 0.447820, Train Acc= 0.79848, Val Loss= 0.460410, Val Acc= 0.78927\n",
      "model saved.\n",
      "Iter 6, Train Loss= 0.445271, Train Acc= 0.80049, Val Loss= 0.458246, Val Acc= 0.79066\n",
      "model saved.\n",
      "Iter 7, Train Loss= 0.443137, Train Acc= 0.80118, Val Loss= 0.456463, Val Acc= 0.79094\n",
      "model saved.\n",
      "Iter 8, Train Loss= 0.441302, Train Acc= 0.80226, Val Loss= 0.454955, Val Acc= 0.79219\n",
      "model saved.\n",
      "Iter 9, Train Loss= 0.439683, Train Acc= 0.80295, Val Loss= 0.453652, Val Acc= 0.79289\n",
      "model saved.\n",
      "Iter 10, Train Loss= 0.438235, Train Acc= 0.80415, Val Loss= 0.452503, Val Acc= 0.79275\n",
      "Iter 11, Train Loss= 0.436926, Train Acc= 0.80502, Val Loss= 0.451479, Val Acc= 0.79310\n",
      "model saved.\n",
      "Iter 12, Train Loss= 0.435733, Train Acc= 0.80558, Val Loss= 0.450554, Val Acc= 0.79359\n",
      "model saved.\n",
      "Iter 13, Train Loss= 0.434629, Train Acc= 0.80597, Val Loss= 0.449714, Val Acc= 0.79421\n",
      "model saved.\n",
      "Iter 14, Train Loss= 0.433605, Train Acc= 0.80683, Val Loss= 0.448945, Val Acc= 0.79442\n",
      "model saved.\n",
      "Iter 15, Train Loss= 0.432649, Train Acc= 0.80711, Val Loss= 0.448234, Val Acc= 0.79498\n",
      "model saved.\n",
      "Iter 16, Train Loss= 0.431750, Train Acc= 0.80764, Val Loss= 0.447573, Val Acc= 0.79491\n",
      "Iter 17, Train Loss= 0.430903, Train Acc= 0.80768, Val Loss= 0.446960, Val Acc= 0.79519\n",
      "model saved.\n",
      "Iter 18, Train Loss= 0.430102, Train Acc= 0.80784, Val Loss= 0.446385, Val Acc= 0.79560\n",
      "model saved.\n",
      "Iter 19, Train Loss= 0.429339, Train Acc= 0.80818, Val Loss= 0.445845, Val Acc= 0.79588\n",
      "model saved.\n",
      "Iter 20, Train Loss= 0.428618, Train Acc= 0.80856, Val Loss= 0.445337, Val Acc= 0.79644\n",
      "model saved.\n",
      "Iter 21, Train Loss= 0.427927, Train Acc= 0.80890, Val Loss= 0.444859, Val Acc= 0.79644\n",
      "Iter 22, Train Loss= 0.427266, Train Acc= 0.80915, Val Loss= 0.444405, Val Acc= 0.79713\n",
      "model saved.\n",
      "Iter 23, Train Loss= 0.426634, Train Acc= 0.80947, Val Loss= 0.443977, Val Acc= 0.79741\n",
      "model saved.\n",
      "Iter 24, Train Loss= 0.426028, Train Acc= 0.81013, Val Loss= 0.443570, Val Acc= 0.79804\n",
      "model saved.\n",
      "Iter 25, Train Loss= 0.425445, Train Acc= 0.81043, Val Loss= 0.443183, Val Acc= 0.79832\n",
      "model saved.\n",
      "Iter 26, Train Loss= 0.424881, Train Acc= 0.81071, Val Loss= 0.442812, Val Acc= 0.79846\n",
      "model saved.\n",
      "Iter 27, Train Loss= 0.424345, Train Acc= 0.81104, Val Loss= 0.442461, Val Acc= 0.79846\n",
      "Iter 28, Train Loss= 0.423819, Train Acc= 0.81136, Val Loss= 0.442125, Val Acc= 0.79866\n",
      "model saved.\n",
      "Iter 29, Train Loss= 0.423314, Train Acc= 0.81170, Val Loss= 0.441803, Val Acc= 0.79880\n",
      "model saved.\n",
      "Iter 30, Train Loss= 0.422823, Train Acc= 0.81196, Val Loss= 0.441496, Val Acc= 0.79901\n",
      "model saved.\n",
      "Iter 31, Train Loss= 0.422351, Train Acc= 0.81214, Val Loss= 0.441202, Val Acc= 0.79887\n",
      "Iter 32, Train Loss= 0.421892, Train Acc= 0.81265, Val Loss= 0.440919, Val Acc= 0.79873\n",
      "Iter 33, Train Loss= 0.421448, Train Acc= 0.81295, Val Loss= 0.440646, Val Acc= 0.79859\n",
      "Iter 34, Train Loss= 0.421014, Train Acc= 0.81317, Val Loss= 0.440385, Val Acc= 0.79853\n",
      "Iter 35, Train Loss= 0.420595, Train Acc= 0.81349, Val Loss= 0.440133, Val Acc= 0.79866\n",
      "Iter 36, Train Loss= 0.420184, Train Acc= 0.81347, Val Loss= 0.439892, Val Acc= 0.79908\n",
      "model saved.\n",
      "Iter 37, Train Loss= 0.419786, Train Acc= 0.81359, Val Loss= 0.439657, Val Acc= 0.79915\n",
      "model saved.\n",
      "Iter 38, Train Loss= 0.419404, Train Acc= 0.81373, Val Loss= 0.439431, Val Acc= 0.79908\n",
      "Iter 39, Train Loss= 0.419027, Train Acc= 0.81387, Val Loss= 0.439213, Val Acc= 0.79908\n",
      "Iter 40, Train Loss= 0.418659, Train Acc= 0.81398, Val Loss= 0.439002, Val Acc= 0.79908\n",
      "Iter 41, Train Loss= 0.418297, Train Acc= 0.81410, Val Loss= 0.438798, Val Acc= 0.79894\n",
      "Iter 42, Train Loss= 0.417951, Train Acc= 0.81424, Val Loss= 0.438599, Val Acc= 0.79915\n",
      "Iter 43, Train Loss= 0.417612, Train Acc= 0.81430, Val Loss= 0.438407, Val Acc= 0.79936\n",
      "model saved.\n",
      "Iter 44, Train Loss= 0.417277, Train Acc= 0.81452, Val Loss= 0.438222, Val Acc= 0.79929\n",
      "Iter 45, Train Loss= 0.416952, Train Acc= 0.81452, Val Loss= 0.438042, Val Acc= 0.79908\n",
      "Iter 46, Train Loss= 0.416631, Train Acc= 0.81460, Val Loss= 0.437867, Val Acc= 0.79915\n",
      "Iter 47, Train Loss= 0.416318, Train Acc= 0.81484, Val Loss= 0.437697, Val Acc= 0.79915\n",
      "Iter 48, Train Loss= 0.416015, Train Acc= 0.81506, Val Loss= 0.437531, Val Acc= 0.79915\n",
      "Iter 49, Train Loss= 0.415718, Train Acc= 0.81512, Val Loss= 0.437372, Val Acc= 0.79915\n",
      "Iter 50, Train Loss= 0.415421, Train Acc= 0.81534, Val Loss= 0.437216, Val Acc= 0.79901\n",
      "Iter 51, Train Loss= 0.415135, Train Acc= 0.81551, Val Loss= 0.437063, Val Acc= 0.79908\n",
      "Iter 52, Train Loss= 0.414853, Train Acc= 0.81583, Val Loss= 0.436915, Val Acc= 0.79929\n",
      "Iter 53, Train Loss= 0.414578, Train Acc= 0.81597, Val Loss= 0.436770, Val Acc= 0.79936\n",
      "Iter 54, Train Loss= 0.414306, Train Acc= 0.81605, Val Loss= 0.436630, Val Acc= 0.79957\n",
      "model saved.\n",
      "Iter 55, Train Loss= 0.414042, Train Acc= 0.81617, Val Loss= 0.436492, Val Acc= 0.79964\n",
      "model saved.\n",
      "Iter 56, Train Loss= 0.413782, Train Acc= 0.81635, Val Loss= 0.436360, Val Acc= 0.80019\n",
      "model saved.\n",
      "Iter 57, Train Loss= 0.413528, Train Acc= 0.81657, Val Loss= 0.436229, Val Acc= 0.79999\n",
      "Iter 58, Train Loss= 0.413274, Train Acc= 0.81675, Val Loss= 0.436102, Val Acc= 0.80006\n",
      "Iter 59, Train Loss= 0.413026, Train Acc= 0.81677, Val Loss= 0.435975, Val Acc= 0.79985\n",
      "Iter 60, Train Loss= 0.412785, Train Acc= 0.81689, Val Loss= 0.435855, Val Acc= 0.79971\n",
      "Iter 61, Train Loss= 0.412543, Train Acc= 0.81709, Val Loss= 0.435736, Val Acc= 0.79971\n",
      "Iter 62, Train Loss= 0.412308, Train Acc= 0.81728, Val Loss= 0.435618, Val Acc= 0.79964\n",
      "Iter 63, Train Loss= 0.412072, Train Acc= 0.81738, Val Loss= 0.435506, Val Acc= 0.79978\n",
      "Iter 64, Train Loss= 0.411844, Train Acc= 0.81756, Val Loss= 0.435393, Val Acc= 0.79978\n",
      "Iter 65, Train Loss= 0.411620, Train Acc= 0.81780, Val Loss= 0.435284, Val Acc= 0.79985\n",
      "Iter 66, Train Loss= 0.411400, Train Acc= 0.81782, Val Loss= 0.435177, Val Acc= 0.79992\n",
      "Iter 67, Train Loss= 0.411182, Train Acc= 0.81794, Val Loss= 0.435072, Val Acc= 0.79999\n",
      "Iter 68, Train Loss= 0.410964, Train Acc= 0.81788, Val Loss= 0.434967, Val Acc= 0.80006\n",
      "Iter 69, Train Loss= 0.410751, Train Acc= 0.81794, Val Loss= 0.434866, Val Acc= 0.80006\n",
      "Iter 70, Train Loss= 0.410539, Train Acc= 0.81802, Val Loss= 0.434767, Val Acc= 0.80013\n",
      "Iter 71, Train Loss= 0.410334, Train Acc= 0.81826, Val Loss= 0.434669, Val Acc= 0.80013\n",
      "Iter 72, Train Loss= 0.410128, Train Acc= 0.81834, Val Loss= 0.434573, Val Acc= 0.80006\n",
      "Iter 73, Train Loss= 0.409924, Train Acc= 0.81838, Val Loss= 0.434479, Val Acc= 0.79999\n",
      "Iter 74, Train Loss= 0.409725, Train Acc= 0.81850, Val Loss= 0.434385, Val Acc= 0.80019\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "val_acc,val_cost,tr_acc,tr_cost = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forget .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmBDy/wEcOceNdiLsnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c4f72150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#softmax x ent logits, 128 hidden (16 before)\n",
    "fig = plt.figure()\n",
    "tr_plot, = plt.plot(range(75),tr_cost[1:],label='train')\n",
    "val_plot, = plt.plot(range(75),val_cost[1:],label='validation')\n",
    "plt.legend(handles=[tr_plot, val_plot]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJiEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c2409790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "tr_plot, = plt.plot(range(75),tr_acc[1:],label='train')\n",
    "val_plot, = plt.plot(range(75),val_acc[1:],label='validation')\n",
    "plt.legend(handles=[tr_plot, val_plot],loc=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c5598750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "tr_plot, = plt.plot(range(1000),tr_cost[1:],label='train')\n",
    "val_plot, = plt.plot(range(1000),val_cost[1:],label='validation')\n",
    "plt.legend(handles=[tr_plot, val_plot]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c4e8ce50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "tr_plot, = plt.plot(range(1000),tr_acc[1:],label='train')\n",
    "val_plot, = plt.plot(range(1000),val_acc[1:],label='validation')\n",
    "plt.legend(handles=[tr_plot, val_plot],loc=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(numpy_file):\n",
    "    predictions = []\n",
    "    # build graph and initialize session\n",
    "    tf.reset_default_graph()\n",
    "    #42 seconds next step\n",
    "    (X,_),_,_,pred_y,_,_,saver = build_graph()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # 18 seconds\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        saver.restore(sess,'/Users/Rutherford/Desktop/rnn models/model.ckpt')\n",
    "        # generate calculations from 2d array of input strings\n",
    "        for row in numpy_file:\n",
    "            str_1,str_2 = row[0],row[1]\n",
    "\n",
    "            # strings identical\n",
    "            if str_1 == str_2:\n",
    "                predictions.append('No error')\n",
    "                continue\n",
    "\n",
    "            # model prediction\n",
    "            try:\n",
    "                #tf.arg_max(pred_y,1),\n",
    "                pred = sess.run([tf.argmax(pred_y,1)],\n",
    "                                feed_dict=\\\n",
    "                                {X: np.asarray(_get_dist(str_1,str_2)).reshape([-1,n_steps,n_input])})\n",
    "                #print(pred)\n",
    "                #predictions.append(str(pred[0][0]+1))\n",
    "                predictions.append(pred[0][0]+1)\n",
    "\n",
    "            # can't predict\n",
    "            except:\n",
    "                predictions.append('Unknown')\n",
    "    \n",
    "    return predictions\n",
    "    #print(','.join(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_x_test = X_in[indices[_validation_test_split_idx:_train_test_split_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = predict(raw_x_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[677,  66],\n",
       "       [136, 121]])"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spaces removed dataset\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133, 750],\n",
       "       [ 11, 106]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative ratio 75 runs\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30, 853],\n",
       "       [  5, 112]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next negative 1-ratio\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[149, 734],\n",
       "       [ 15, 102]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next negative ratio\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[883,   0],\n",
       "       [111,   6]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next 1-ratio\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[881,   2],\n",
       "       [115,   2]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio weight\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[882,   1],\n",
       "       [117,   0]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.05 weight 20 runs\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[883,   0],\n",
       "       [117,   0]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .05 weight 20 runs\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93, 790],\n",
       "       [ 10, 107]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -.05 weight 20 runs\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14, 869],\n",
       "       [  3, 114]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-3.5 weight first run (accuracy goes down, unsurprisingly)\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[865,  18],\n",
       "       [ 78,  39]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#other weighted\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[866,  17],\n",
       "       [ 81,  36]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weighted\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[867,  16],\n",
       "       [ 79,  38]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#978\n",
    "confusion_matrix(y_test_res[:1000],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 24,  34,  41,  44,  45,  60,  77,  87,  94, 108, 127, 149, 168,\n",
       "        176, 185, 187, 191, 218, 222, 253, 279, 290, 305, 307, 313, 324,\n",
       "        330, 346, 358, 375, 402, 417, 421, 440, 441, 459, 497, 504, 510,\n",
       "        551, 562, 578, 605, 619, 625, 626, 641, 649, 654, 657, 673, 678,\n",
       "        692, 701, 733, 750, 757, 762, 787, 802, 817, 820, 821, 825, 831,\n",
       "        840, 855, 859, 876, 880, 909, 933, 942, 943, 947, 954, 975, 977, 981]),)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((np.asarray(preds)==1) & (y_test_res[:1000]==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tester = np.genfromtxt('/Users/Rutherford/Desktop/data/data.csv',dtype='str',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,1,1,1,2,1,2,No error,1,1,1,1,1,No error,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n"
     ]
    }
   ],
   "source": [
    "predict(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def check_results(y_test,result_list):\n",
    "    \"\"\"\n",
    "    Prints a confusion matrix of performance on the test set,\n",
    "    and instantiates lists of True Positive, True Negative,\n",
    "    False Positive, and False Negative for inspection as\n",
    "    self._TP, self._TN, self._FP, self._FN.\n",
    "    \"\"\"\n",
    "\n",
    "    # print confusion matrix\n",
    "    #true_y_labels = np.array(y_test[:,1])\n",
    "    true_y_labels = np.argmax(y_test,1)+1\n",
    "    print('\\t\\tPredicted:')\n",
    "    print('\\t\\tmin. maj.')\n",
    "    print('Actual:\\t min.',\n",
    "          confusion_matrix(true_y_labels,result_list)[0])\n",
    "    print('    \\t maj.',\n",
    "          confusion_matrix(true_y_labels,result_list)[1])\n",
    "\n",
    "    # identify predicted and true positives and negatives\n",
    "    predicted_pos = np.where(result_list[0]==1)\n",
    "    predicted_neg = np.where(result_list[0]==0)\n",
    "    actual_pos = np.where(np.argmax(y_test,1)==1)\n",
    "    actual_neg = np.where(np.argmax(y_test,1)==0)\n",
    "\n",
    "    # indices of shuffled and split data (just y_test)\n",
    "    true_pos = np.intersect1d(predicted_pos,actual_pos).tolist()\n",
    "    true_neg = np.intersect1d(predicted_neg,actual_neg).tolist()\n",
    "    false_pos = np.intersect1d(predicted_pos,actual_neg).tolist()\n",
    "    false_neg = np.intersect1d(predicted_neg,actual_pos).tolist()\n",
    "    y_indices = indices[_validation_test_split_idx:\n",
    "                                  _train_test_split_idx]\n",
    "\n",
    "    raw_X = X_in\n",
    "    \n",
    "    # create lists of true and false positives and negatives\n",
    "    TP = [list(raw_X[y_indices[i]]) for i in true_pos]\n",
    "    TN = [list(raw_X[y_indices[i]]) for i in true_neg]\n",
    "    FP = [list(raw_X[y_indices[i]]) for i in false_pos]\n",
    "    FN = [list(raw_X[y_indices[i]]) for i in false_neg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = [1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,1,1,1,2,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,2,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,2,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_res = np.argmax(y_test,1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[432,  10],\n",
       "       [ 35,  23]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_res[:500],res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-303c00781b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# to see if there's a difference when n_input and n_steps are flipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0mTo\u001b[0m \u001b[0mclassify\u001b[0m \u001b[0mimages\u001b[0m \u001b[0musing\u001b[0m \u001b[0ma\u001b[0m \u001b[0mrecurrent\u001b[0m \u001b[0mneural\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mconsider\u001b[0m \u001b[0mevery\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpixels\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mBecause\u001b[0m \u001b[0mMNIST\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mthen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# to see if there's a difference when n_input and n_steps are flipped\n",
    "tf.reset_default_graph()\n",
    "'''\n",
    "To classify images using a recurrent neural network, we consider every image\n",
    "row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "handle 28 sequences of 28 steps for every sample.\n",
    "'''\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10#0000\n",
    "batch_size = 64\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 608 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 1 # timesteps\n",
    "num_hidden = 4#128 # hidden layer num of features\n",
    "n_classes = 2 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "start = time()\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('variables initialized ',time()-start)\n",
    "    start_end = zip(range(0,len(x_train),batch_size),\n",
    "               range(batch_size,len(x_train)+1,\n",
    "                     batch_size))\n",
    "    # Keep training until reach max iterations\n",
    "    #while step * batch_size < training_iters:\n",
    "    \n",
    "    x_batch = x_train.reshape((-1,n_steps,n_input))\n",
    "    print('x batch created ',time()-start)\n",
    "    for pass_i in range(training_iters):\n",
    "        for (s,e) in start_end:\n",
    "            if str(s)[-2:] == '00':\n",
    "                print(s,time()-start)\n",
    "        \n",
    "            \"\"\"batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # Reshape data to get 28 seq of 28 elements\n",
    "            batch_x = batch_x.reshape((batch_size, n_steps, n_input))\"\"\"\n",
    "            \n",
    "            ######x_batch = x_train[s:e,].reshape((batch_size,n_steps,n_input))\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(optimizer, feed_dict={x: x_batch[s:e,:,:], y: y_train[s:e]})\n",
    "            # Calculate batch accuracy\n",
    "            #train_acc = sess.run(accuracy, feed_dict={x: x_batch, y: y_train[s:e]})\n",
    "            # Calculate batch loss\n",
    "            #train_loss = sess.run(cost, feed_dict={x: x_batch, y: y_train[s:e]})\n",
    "            sess.run(accuracy, feed_dict={x: x_batch[s:e,:,:], y: y_train[s:e]})\n",
    "        print('done minibatching')\n",
    "        loss = sess.run(cost, feed_dict={x: x_batch, y: y_train})\n",
    "        acc = sess.run(accuracy, feed_dict={x: x_batch, y: y_train})\n",
    "        print(\"Iter \" + str(pass_i) + \", Train Loss= \" + \\\n",
    "              \"{:.6f}\".format(loss) + \", Train Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))\n",
    "        #if pass_i % display_step == 0:\n",
    "        #    x_test_correct_shape = x_train.reshape((-1, n_steps, n_input))\n",
    "        #    # Calculate batch accuracy\n",
    "        #    acc = sess.run(accuracy, feed_dict={x: x_test_correct_shape, y: y_test})\n",
    "        #    # Calculate batch loss\n",
    "        #    loss = sess.run(cost, feed_dict={x: x_test_correct_shape, y: y_test})\n",
    "        #    print(\"Iter \" + str(pass_i) + \", Test Loss= \" + \\\n",
    "        #          \"{:.6f}\".format(loss) + \", Test Accuracy= \" + \\\n",
    "        #          \"{:.5f}\".format(acc))\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputs and outputs (latter are one-hot vectors)\n",
    "X = tf.placeholder(tf.float32, shape=[None,608])#612])#12])#\"\"\"612])\"\"\"\n",
    "Y = tf.placeholder(tf.float32, shape=[None,2])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "glob_step = tf.Variable(0,dtype=tf.float32,trainable=False)\n",
    "\n",
    "weight_shape1 = [608,256]#612 #\"\"\"12\"\"\"\n",
    "weight_shape2 = [256,128]\n",
    "weight_shape3 = [128,16]\n",
    "weight_shape4 = [16,2]\n",
    "\n",
    "[n_inputs1,n_outputs1,n_inputs3,n_outputs3,n_outputs_final] =             weight_shape1[0],weight_shape1[1],weight_shape3[0],             weight_shape3[1],weight_shape4[1]\n",
    "\n",
    "init_range1 = tf.sqrt(6.0/(n_inputs1+n_outputs1))\n",
    "init_range2 = tf.sqrt(6.0/(n_outputs1+n_inputs3))\n",
    "init_range3 = tf.sqrt(6.0/(n_inputs3+n_outputs3))\n",
    "init_range4 = tf.sqrt(6.0/(n_outputs3+n_outputs_final))\n",
    "w1 = tf.Variable(tf.random_uniform(weight_shape1,\n",
    "                                   -init_range1,init_range1),name='w1')\n",
    "w2 = tf.Variable(tf.random_uniform(weight_shape2,\n",
    "                                   -init_range2,init_range2),name='w2')\n",
    "w3 = tf.Variable(tf.random_uniform(weight_shape3,\n",
    "                                   -init_range3,init_range3),name='w3')\n",
    "w4 = tf.Variable(tf.random_uniform(weight_shape4,\n",
    "                                   -init_range4,init_range4),name='w4')\n",
    "b = tf.Variable(tf.constant(.1,shape=[n_outputs_final]))\n",
    "\n",
    "\n",
    "# network - batch normalization in training, relu activations\n",
    "dot1 = tf.matmul(X,w1)\n",
    "batch_normed1 = self._batch_norm_wrapper(dot1,training)\n",
    "rel1 = tf.nn.relu(batch_normed1)\n",
    "\n",
    "dot2 = tf.matmul(rel1,w2)\n",
    "batch_normed2 = self._batch_norm_wrapper(dot2,training)\n",
    "rel2 = tf.nn.relu(batch_normed2)\n",
    "\n",
    "dot3 = tf.matmul(rel2,w3)\n",
    "batch_normed3 = self._batch_norm_wrapper(dot3,training)\n",
    "rel3 = tf.nn.relu(batch_normed3)\n",
    "\n",
    "# softmax layer\n",
    "logits = tf.matmul(rel3,w4)+b\n",
    "probs_x = tf.nn.softmax(logits)\n",
    "\n",
    "# cost:\n",
    "#    per pair\n",
    "rows_of_cost =             tf.nn.softmax_cross_entropy_with_logits(logits,Y,\n",
    "                                            name='rows_of_cost')\n",
    "#    average over all pairs\n",
    "cost = tf.reduce_mean(rows_of_cost,reduction_indices=None,\n",
    "                      keep_dims=False,name='cost')\n",
    "\n",
    "# gradients and training\n",
    "opt = tf.train.AdagradOptimizer(learning_rate=lr)\n",
    "train_op = opt.minimize(cost,global_step=glob_step,\n",
    "                        var_list=[w1,w2,w3,w4,b])\n",
    "\n",
    "# predictions and accuracy\n",
    "correct_prediction = tf.equal(tf.arg_max(probs_x,1),tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "#return (X,Y),cost,train_op,accuracy,probs_x,lr,tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from rnnRecurrenceFcn import fLSTM\n",
    "\n",
    "log_dir = \"logs/\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def data_gen(batch_size, seq_len):\n",
    "    x = np.array(np.random.normal(size=(batch_size, seq_len)), dtype=np.float32)\n",
    "    #x = np.ones((batch_size, seq_len), dtype=np.float32)\n",
    "    y = np.sum(x, axis=1)\n",
    "    x = x.reshape([batch_size, seq_len, 1])\n",
    "    y = y.reshape([batch_size, 1])\n",
    "    return x, y\n",
    "\n",
    "#replace with placeholders\n",
    "inputSize = 1\n",
    "hiddenSize = 32\n",
    "targetSize = 1\n",
    "mBatch = 100\n",
    "\n",
    "input_size = inputSize\n",
    "hidden_size = hiddenSize\n",
    "target_size = targetSize\n",
    "\n",
    "# Weights for output layers\n",
    "Wo = tf.Variable(tf.truncated_normal([hidden_size, target_size], mean=0, stddev=.01), name=\"Wo\")\n",
    "bo = tf.Variable(tf.truncated_normal([target_size], mean=0, stddev=.01), name=\"bo\")\n",
    "\n",
    "initHidden = tf.placeholder(tf.float32, shape = [None, 2*hidden_size])\n",
    "inputs = tf.placeholder(tf.float32, shape=[None, None, input_size], name='inputs')\n",
    "inputs_ = tf.transpose(inputs, perm=[1,0,2])\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=[None, target_size])\n",
    "\n",
    "initial_hidden = initHidden\n",
    "print(initial_hidden)\n",
    "#define recursion for scan function\n",
    "fRScan = fLSTM(inputSize, hiddenSize)\n",
    "\n",
    "#hidden state sequence\n",
    "all_hidden_states = tf.scan(fRScan, inputs_, initializer=initial_hidden, name=\"LSTMStates\")\n",
    "\n",
    "#extract last hidden state\n",
    "last_hidden_state = tf.reverse(all_hidden_states, [True, False, False])[0, :, :]\n",
    "lastH, lastC = tf.split(1, 2, last_hidden_state)\n",
    "#develop logit from last hidden state\n",
    "last_output = tf.matmul(lastH, Wo) + bo\n",
    "\n",
    "#loss definition for gradients\n",
    "loss = tf.reduce_mean(tf.square(y - last_output))\n",
    "\n",
    "#rms error for printing\n",
    "rms_error = tf.sqrt(loss)\n",
    "\n",
    "#training function\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    #summary_op = tf.merge_all_summaries()\n",
    "    writer = tf.train.SummaryWriter(log_dir, sess.graph)\n",
    "    #print(\"initial_hidden: %s\" % initial_hidden)\n",
    "    # initial value for hidden state\n",
    "    # Keep this value to start for zero for all subsequent iterations\n",
    "    # Set to lastHiddenState after each training step\n",
    "    iHid = np.zeros([mBatch, 2*hiddenSize], dtype=np.float32)\n",
    "    print(iHid.shape)\n",
    "\n",
    "    for epoch in range(4096):  # 120\n",
    "        X_train, y_train = data_gen(mBatch, 10)\n",
    "        X_test, y_test = data_gen(mBatch, 10)\n",
    "        ts, lhs = sess.run([train_step, last_hidden_state], {inputs: X_train, y: y_train, initHidden: iHid})\n",
    "        #iHid = lhs  #This line initializes each LSTM with the value at the end of last sequence of iterations\n",
    "        #writer.add_summary(summary_str, epoch)\n",
    "\n",
    "        Loss = str(sess.run(loss, {inputs: X_train, y: y_train, initHidden: iHid}))\n",
    "        Train_error = str(sess.run(rms_error, {inputs: X_train, y: y_train, initHidden: iHid}))\n",
    "        Test_error = str(sess.run(rms_error, {inputs: X_test, y: y_test, initHidden: iHid}))\n",
    "\n",
    "        sys.stdout.flush()\n",
    "        print(\"\\rIteration: %s Loss: %s Train Error: %s Test Error: %s\" %\n",
    "              (epoch, Loss, Train_error, Test_error)),\n",
    "    sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
